% -*- TeX -*-
\documentclass{article}

% --- preamble from template ---
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{makecell}

\usepackage{dan2e}

\makeatletter
\@ifundefined{@Russian}{\newif\if@Russian \@Russiantrue}{}
\@ifundefined{@TVP}     {\newif\if@TVP    \@TVPfalse}{}
\makeatother

\theoremstyle{definition}
\newtheorem{defi}{Определение}
\theoremstyle{plain}
\newtheorem{remark}{Пример}
\newtheorem{theorem}{Теорема}
\newtheorem{OldTheorem}{Теорема}
\renewcommand{\theOldTheorem}{\Alph{OldTheorem}}

\newtheorem{Theorem}{Теорема}
\renewcommand{\theTheorem}{\arabic{theorem}$^\prime$}

% --- журнал‑специфичные метаданные (ДОЛЖНЫ стоять **до** \begin{document}) ---
\begin{document}
\Volume{505}
\Year{2025}
\Pages{46--49}

\udk{517.54}

\title{Реферирование художественной литературы посредством больших языковых моделей}

\author{Д.\,А.~Григорьев\Addressmark[1]\Emailmark[1], Д.\,И.~Чернышев\Addressmark[1]\Emailmark[2]}

\Addresstext[1]{Московский государственный университет им.~М.\,В.~Ломоносова, Москва, Россия}

\Emailtext[1]{dagrig14@yandex.ru}
\Emailtext[2]{chdanorbis@yandex.ru}

\markboth{Д.\,А.~Григорьев, Д.\,И.~Чернышев}{Оценка общих и специальных знаний в больших языковых моделях}

\presentedby{Представлено кем-то}

% Даты публикации (пример)
\dateA{16.08.2025}
\dateB{20.08.2025}
\dateC{31.08.2025}

% -------------------------------------------------------


\maketitle

\begin{abstract}
Работа исследует методы сжатия художественных текстов с помощью языковых моделей и предлагает улучшенные подходы для точного реферирования в условиях ограниченного контекста.
\end{abstract}

\begin{keywords}
LLM, реферирование, литература, книги, краткий пересказ
\end{keywords}

% ================= ВВЕДЕНИЕ =================
\section*{Введение}
\subsection*{Реферирование художественной литературы}
Автоматическое реферирование текста — одна из ключевых задач в области обработки естественного языка. Суть этой задачи заключается в создании информативной аннотации исходного текста с сохранением основного смысла содержания. В последние годы, с появлением больших языковых моделей, резко возрос интерес к автоматизации реферирования в самых разных жанрах текстов, включая художественные произведения. В отличие от научных, новостных или технических текстов, художественные произведения характеризуются высокой степенью стилистической и семантической сложности. Нелинейность повествования, образность, метафоричность и стилистические приёмы делают задачу написания краткого содержания особенно трудоёмкой. Ограниченное контекстное окно современных моделей дополнительно осложняет работу с длинными произведениями.

Теоретически автоматическое реферирование может выполняться двумя основными способами: извлекающим (выбор ключевых фрагментов текста) и абстрактивным (генерация нового текста на основе содержания оригинала). Для художественной литературы более уместен второй подход, поскольку он позволяет передать смысл и стиль произведения, не нарушая его целостности.

% ================= НАБОР ДАННЫХ =================
\section*{Набор данных}
\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/text_len2.png}
        \caption{Гистограмма с количеством слов в текстах}
        \label{fig:text_len}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/ann_len2.png}
        \caption{Гистограмма с количеством слов в аннотациях}
        \label{fig:ann_len}
    \end{minipage}
\end{figure}

На момент начала исследования не существовало открытых и репрезентативных корпусов, предназначенных специально для задачи реферирования художественных текстов на русском языке. С целью проведения экспериментов и оценки различных подходов к генерации аннотаций был создан собственный корпус, состоящий из художественных текстов и соответствующих кратких пересказов. 
В качестве источника для аннотаций был выбран ресурс «Народный Брифли»~\cite{Briefly} — платформа, где пользователи публикуют краткие пересказы литературных произведений. 
Несмотря на вариативность качества и стиля пользовательских аннотаций и наличие нерелевантной информации, такой как учебные вопросы или редакторские замечания, после тщательной предварительной обработки удалось получить достаточно надёжный и чистый набор данных.
Художественные тексты были отобраны из электронной библиотеки LibRuSec — одного из крупнейших русскоязычных ресурсов художественной литературы. 
Отбор произведений осуществлялся на основании наличия аннотаций на выбранном ресурсе \cite{Briefly}. Каждый текст проходил автоматическую предварительную обработку: удалялась метаинформация (например, заголовки, описания глав и технические вставки), 
после чего текст форматировался в единый стандартизированный вид, подходящий для дальнейшего использования в моделях.
Важно отметить, что при создании корпуса использовались только тексты, находящиеся в общественном достоянии или распространяемые свободно с разрешения правообладателей, что обеспечивает соблюдение требований авторского права.
\\Получившийся корпус включал в себя:
\begin{itemize}
  \item более 600 пользовательских пересказов с ресурса «Народный Брифли»;
  \item исходные произведения из электронной библиотеки LibRuSec;
\end{itemize}
Тексты аннотаций проходили автоматическую очистку от HTML‑тегов, комментариев и служебных пометок с помощью LLM~Meta--Llama~3--70B--Instruct. Затем производился поиск по датасету LibRuSec и собиралась коллекция, состоящая из пар "текст книги - аннотация".
На рисунке \ref{fig:text_len} показано распределение текстов в зависимотсти от количества слов в них. На рисунке \ref{fig:ann_len} аналогичная информация об аннотациях.

% ================= ПРИМЕНЕНИЕ МЕТОДОВ =================
\section*{Методология}

\subsection*{Базовые и модифицированные стратегии}

\subsubsection*{Иерархический метод}
Пусть входной текст $D$ имеет длину $L\gg W$, где $W$ — размер контекстного окна LLM, а $C<W$ — длина одного чанка. Обозначим уровень иерархии $l=0,1,\dots,L$, и гиперпараметр контроля длины на уровне $l$ как $G_l$. 

\begin{enumerate}
  \item Разбиваем $D$ на $n_0 = \bigl\lceil L / C\bigr\rceil$ чанков 
  \[
    C_i,\quad i=1,\dots,n_0.
  \]
  \item На уровне $l=0$ для каждого чанка генерируем локальную аннотацию
  \[
    S_i^{(0)} = \mathrm{Summarize}(C_i), 
    \quad i=1,\dots,n_0.
  \]
  \item Для $l=1,2,\dots$ до тех пор, пока не останется единственной аннотации:
  \begin{itemize}
    \item Задаём порог длины  
    \[
      T_l = W \;-\; G_l.
    \]
    \item Инициализируем $i\leftarrow1$, $j\leftarrow1$.
    \item Пока $i \le n_{l-1}$:
      \begin{itemize}
        \item Найдём наибольшее $m\ge1$, такое что
        \[
          \sum_{t=i}^{i+m-1} \bigl|S_t^{(l-1)}\bigr| \;\le\; T_l.
        \]
        \item Объединяем эти аннотации и генерируем
        \[
          S_j^{(l)} \;=\;
          \mathrm{Summarize}\bigl(S_i^{(l-1)}\oplus\cdots\oplus S_{i+m-1}^{(l-1)}\bigr).
        \]
        \item Обновляем $i\leftarrow i+m,\; j\leftarrow j+1$.
      \end{itemize}
    \item Получаем $n_l=j-1$ аннотаций уровня $l$.
  \end{itemize}
  \item Итоговая аннотация — единственный элемент $S^{(L)}$.
\end{enumerate}

\subsubsection*{«Чертёжный» метод (Text‑Blueprint)}
Метод строит промежуточный план в виде вопросов и ответов перед генерацией текста. 
Для всего текста $T$ или каждого чанка модель последовательно:
\begin{enumerate}
  \item Генерирует список вопросов $\{q_i\}$, охватывающих ключевые элементы сюжета.
  \item Для каждого $q_i$ формирует краткий ответ $a_i$.
  \item Собирает последовательность $(q_1,a_1),\dots,(q_m,a_m)$ как «чертёж».
  \item По этому «чертежу» генерирует итоговое резюме: 
    \[
      S = \mathrm{LLM}\bigl((q_1,a_1)\oplus\dots\oplus(q_m,a_m)\bigr).
    \]
\end{enumerate}

\subsubsection*{Иерархический метод с фильтрацией узлов}
Для исключения «воды» и дублирующих фрагментов на каждом уровне иерархии мы теперь выполняем глобальную проверку семантической близости между всеми промежуточными аннотациями. Алгоритм следующий:

\begin{enumerate}
  \item Пусть на текущем уровне имеются аннотации $\{S_i\}_{i=1}^n$.
  \item Вычисляем эмбеддинги $\mathbf{e}_i = \mathrm{Encoder}(S_i)$ и нормируем их.
  \item Составляем матрицу косинусных сходств
    \[
      M_{ij} = \frac{\mathbf{e}_i \cdot \mathbf{e}_j}{\|\mathbf{e}_i\|\;\|\mathbf{e}_j\|},
      \quad i,j=1,\dots,n.
    \]
  \item Для каждой аннотации $S_j$ находим
    \[
      m_j = \max_{\,i<j} M_{ji},
    \]
    то есть максимальную степень схожести с любой предыдущей в списке.
  \item Если $m_j < \theta$ (где $\theta=0.85$), то сохраняем $S_j$, иначе отбрасываем.
  \item Гарантируем, что $S_1$ всегда остаётся, чтобы не получилось пустого уровня.
\end{enumerate}
Эмбеддинги получаются с помощью SentenceTransformer (модель USER-bge-m3) и вычисляются на GPU, что обеспечивает высокую скорость обработки.

\subsubsection*{«Чертёжный» метод с кластеризацией вопросов}
Для снижения числа запросов к модели и повышения структурности:
\begin{enumerate}
  \item Для каждого чанка $C_i$ сгенерировать вопросы $Q_i = \{q_{i1},\dots,q_{im}\}$.
  \item Вычислить эмбеддинги $E_i = \{\mathbf{e}_{i1},\dots,\mathbf{e}_{im}\}$.
  \item Объединить все $\{\mathbf{e}_{ij}\}$ и применить алгоритм K‑means на $r$ кластеров.
  \item Из каждого кластера $c$ случайно выбрать 10–30 вопросов.
  \item Для кластера $c$ сформировать обобщённый вопрос $Q_c^*$:
    \[
      Q_c^* = \mathrm{LLM}\bigl(\,\text{concat}(q\in c)\bigr).
    \]
  \item Использовать $\{Q_c^*\}$ как чертёж для генерации итоговой аннотации.
\end{enumerate}

Такой подход позволяет уменьшить число обращений к LLM, что позволяет ускорить скорость генераций, как будет показано в таблице \ref{tab:results_models}.

\section*{Оценивание методов}

Для объективного сравнения описанных подходов и моделей в задаче реферирования художественных текстов использовались четыре группы метрик.

\textbf{ROUGE-L} — основана на длине наибольшей общей подпоследовательности (LCS) между сгенерированной аннотацией $S$ и эталонной $R$:
    \[
      \text{Precision} = \frac{\mathrm{LCS}(S,R)}{|S|},\quad
      \text{Recall} = \frac{\mathrm{LCS}(S,R)}{|R|},
    \]
    \[
      \text{ROUGE‑L} = \frac{2\;\text{Precision}\;\cdot\;\text{Recall}}{\text{Precision} + \text{Recall}}.
    \]
\\ \textbf{BERTScore} — семантическое качество на уровне токенов. Для каждой пары токенов предсказания и эталона вычисляется косинусное сходство их эмбеддингов в модели USER‑bge‑m3. Затем:
    \[
      P = \frac{1}{|S|}\sum_{t\in S}\max_{u\in R}\!\mathrm{sim}(e_t, e_u),\quad
      R = \frac{1}{|R|}\sum_{u\in R}\max_{t\in S}\!\mathrm{sim}(e_u, e_t),
    \]
    \[
      \text{BERTScore} = \frac{2\,P\,R}{P+R}.
    \]
\\ \textbf{Полнота покрытия ключевых вопросов (Coverage)} — доля заранее сгенерированных по эталонному тексту вопросов, на которые модель «отвечает» в аннотации:
    \[
      \text{Coverage} = \frac{\#\{q_i\colon P(\text{“да”}\mid q_i,S)\!>\!0.75\}}{N},
    \]
    где $N$ — общее число вопросов, а $P(\text{“да”}\mid q_i,S)$ — вероятность наличия ответа на вопрос $q_i$ в тексте $S$, оцененная LLM.
\\ \textbf{Совпадение ответов (AnswerSimilarity)} — среднее семантическое сходство между сгенерированными ответами $a_i^{\text{pred}}$ и эталонными $a_i^{\text{ref}}$ на те же ключевые вопросы:
    \[
      \text{AnswerSimilarity}
      = \frac{1}{N}\sum_{i=1}^N \mathrm{sim}\bigl(a_i^{\text{pred}},\,a_i^{\text{ref}}\bigr),
    \]
    где $\mathrm{sim}$ — косинусное сходство эмбеддингов, полученных через USER‑bge‑m3.


Использование нескольких метрик, учитывающих как поверхностное совпадение текста (ROUGE‑L), так и глубокое семантическое сходство (BERTScore, AnswerSimilarity), а также степень охвата заранее заданных вопросов (Coverage), обеспечивает всестороннюю и устойчивую оценку качества аннотаций.```



\section*{Результаты}

В таблице \ref{tab:results_models} приведены сравнительные результаты работы описанных выше методов генерации кратких пересказов художественных текстов.
Для каждой из исллдованных моделей измерялись метрики качеств  и время выполнеия в зависимости от метода: базовые чертежный и иерархический методы, а также их усовершенствованные версии \- 
чертежный метод с кластеризацией вопросов и иерархический метод с фильтрацией узлов.

\begin{table}[ht]
\centering
\small                       % уменьшили шрифт (можно \footnotesize)
\setlength{\tabcolsep}{4pt}  % сузили горизонтальные отступы между колонками
%\renewcommand{\arraystretch}{0.9} % можно ещё уплотнить строки

\caption{Результаты по методам и моделям}
\label{tab:results_models}

\begin{tabular}{llcccc}      % 2 текстовых столбца + 4 числовых
\toprule
Модель & Метрики &
\makecell{Чертежный} &
\makecell{Чертежный \\ с кластеризацией} &
\makecell{Иерархический} &
\makecell{Иерархический \\ с фильтрацией} \\
\midrule
\multirow{2}{*}{RuadaptQwen2.5-7B-Lite-Beta}
 & bertscore & 56.1 ± 4.9 & 54.0 ± 4.0 & 55.4 ± 2.9 & 55.8 ± 2.9 \\
 & rouge-l   & 10.1 ± 3.9 & 7.7 ± 2.8 & 8.6 ± 2.5 & 8.7 ± 2.5 \\
 & time & 126.84 & 76.66 & 68.86 & 53.59 \\
\midrule
\multirow{2}{*}{RuadaptQwen3-32B-Instruct-v2}
& bertscore & 58.9 ± 3.6 & 55.3 ± 3.3 & 57.3 ± 2.9 & 57.7 ± 3.3 \\
& rouge-l   & 10.6 ± 3.2 & 7.8 ± 2.1 & 11.0 ± 2.4 & 10.7 ± 2.4 \\
& time & 376.28 & 271.42 & 211.72 & 159.11 \\
\midrule
\multirow{2}{*}{yagpt5lite}
 & bertscore & 61.1 ± 3.8 & 61.5 ± 3.3 & 62.5 ± 3.5 & 62.1 ± 3.2 \\
 & rouge-l & 15.8 ± 5.1 & 14.3 ± 4.4 & 16.9 ± 5.1 & 16.4 ± 4.7 \\
 & time & 113.34 & 42.15 & 31.02 & 27.39 \\
\midrule
\multirow{2}{*}{Qwen3-235B-A22B}
 & bertscore & 61.6 ± 3.3 & 59.3 ± 3.4 & 61.2 ± 3.0 & 60.9 ± 2.7 \\
 & rouge-l & 15.8 ± 4.5 & 12.2 ± 3.6 & 14.9 ± 4.0 & 14.8 ± 3.7 \\
 & time & 200.30 & 149.11 & 103.49 & 83.06 \\
\midrule
\multirow{2}{*}{DeepSeek V3}
 & bertscore & 58.0 ± 4.0 & 58.4 ± 3.6 & 60.0 ± 3.1 & 60.0 ± 2.9 \\
 & rouge-l & 12.6 ± 4.6 & 11.2 ± 3.9 & 13.7 ± 3.9 & 13.5 ± 3.7 \\
 & time & 315.67 & 132.60 & 196.77 & 147.21 \\
\midrule
\multirow{2}{*}{tpro}
 & bertscore & 59.0 ± 4.9 & 58.2 ± 3.7 & 59.4 ± 3.0 & 59.5 ± 3.3 \\
 & rouge-l & 14.7 ± 4.9 & 11.8 ± 3.9 & 13.8 ± 3.1 & 13.5 ± 3.0 \\
 & time & 259.35 & 161.33 & 276.45 & 230.21 \\ 
\bottomrule
\end{tabular}
\end{table}

Как видно из таблицы \ref{tab:results_models}, модифицированные варианты методов действительно существенно ускоряют обработку: среднее время генерации сокращается в 1.5-3 раза в зависимости от модели (например, DeepSeek V3: 315.67 $\implies$ 132.60)
Однако выигрыш по скорости сопровождается умеренным снижением качества: падение BERTScore и ROUGE-L чаще всего укладывается в 1-2 пункта и находится в пределах стандартных отклонений.
% -------------------------------------------------------



%-------РЕФЕРЕНСЫ---------
\begin{thebibliography}{99}
\bibitem{Briefly}
\textit{Народный Брифли.}  
Электронная библиотека кратких пересказов литературных произведений.  
\url{https://wiki.briefly.ru/} (дата обращения: 16.07.2025).

\end{thebibliography}

\renewcommand\refname{References}


\begin{thebibliography}{99}
\bibitem{Briefly_e}
\textit{Народный Брифли.}  
Электронная библиотека кратких пересказов литературных произведений.  
\url{https://wiki.briefly.ru/} (дата обращения: 16.07.2025).

\end{thebibliography}

\end{document}