% -*- TeX -*-
\documentclass{article}

% --- preamble from template ---
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{makecell}
\usepackage[section]{placeins}

\usepackage{dan2e}

\makeatletter
\@ifundefined{@Russian}{\newif\if@Russian \@Russiantrue}{}
\@ifundefined{@TVP}     {\newif\if@TVP    \@TVPfalse}{}
\makeatother

\theoremstyle{definition}
\newtheorem{defi}{Определение}
\theoremstyle{plain}
\newtheorem{remark}{Пример}
\newtheorem{theorem}{Теорема}
\newtheorem{OldTheorem}{Теорема}
\renewcommand{\theOldTheorem}{\Alph{OldTheorem}}

\newtheorem{Theorem}{Теорема}
\renewcommand{\theTheorem}{\arabic{theorem}$^\prime$}

\begin{document}
\Volume{505}
\Year{2025}
\Pages{46--49}

\udk{517.54}

\title{Реферирование художественной литературы посредством больших языковых моделей}

\author{Д.\,А.~Григорьев\Addressmark[1]\Emailmark[1], Д.\,И.~Чернышев\Addressmark[1]\Emailmark[2]}

\Addresstext[1]{Московский государственный университет им.~М.\,В.~Ломоносова, Москва, Россия}

\Emailtext[1]{dagrig14@yandex.ru}
\Emailtext[2]{chdanorbis@yandex.ru}

\markboth{Д.\,А.~Григорьев, Д.\,И.~Чернышев}{Оценка общих и специальных знаний в больших языковых моделях}

\presentedby{Представлено кем-то}

\dateA{16.08.2025}
\dateB{20.08.2025}
\dateC{31.08.2025}

\alttitle{Evaluating general and special knowledge in large language models for Russian language through replication of encyclopedia articles}

\altauthor{D.\,A.~Grigoriev\Addressmark[a]\Emailmark[1], D.\,I.~Chernyshev\Addressmark[a]\Emailmark[2]}

\altAddresstext[a]{Lomonosov Moscow State University, Moscow Center for Fundamental and Applied Mathematics, \\ Moscow, Russian Federation}

\altpresentedby{man who sold the world}


\maketitle

\begin{abstract}
Работа исследует методы сжатия художественных текстов с помощью языковых моделей и предлагает улучшенные подходы для точного реферирования в условиях ограниченного контекста.
\end{abstract}

\begin{keywords}
LLM, реферирование, литература, книги, краткий пересказ
\end{keywords}

\begin{altabstract}
This work explores methods for compressing literary texts using language models and proposes improved approaches for accurate summarization under limited context conditions.
\end{altabstract}

\begin{altkeywords}
LLM, summarization, literature, books, brief retelling
\end{altkeywords}


% ================= ВВЕДЕНИЕ =================
\section*{Введение}
\subsection*{Реферирование художественной литературы}
Автоматическое реферирование текста — одна из ключевых задач в области обработки естественного языка. Суть этой задачи заключается в создании информативной аннотации исходного текста с сохранением основного смысла содержания. В последние годы, с появлением больших языковых моделей, резко возрос интерес к автоматизации реферирования в самых разных жанрах текстов, включая художественные произведения. В отличие от научных, новостных или технических текстов, художественные произведения характеризуются высокой степенью стилистической и семантической сложности. Нелинейность повествования, образность, метафоричность и стилистические приёмы делают задачу написания краткого содержания особенно трудоёмкой. Ограниченное контекстное окно современных моделей дополнительно осложняет работу с длинными произведениями.

Теоретически автоматическое реферирование может выполняться двумя основными способами: извлекающим (выбор ключевых фрагментов текста) и абстрактивным (генерация нового текста на основе содержания оригинала). Для художественной литературы более уместен второй подход, поскольку он позволяет передать смысл и стиль произведения, не нарушая его целостности.

% ================= НАБОР ДАННЫХ =================
\section*{Набор данных}
\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/text_len2.png}
        \caption{Гистограмма с количеством слов в текстах}
        \label{fig:text_len}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/ann_len2.png}
        \caption{Гистограмма с количеством слов в аннотациях}
        \label{fig:ann_len}
    \end{minipage}
\end{figure}

На момент начала исследования не существовало открытых и репрезентативных корпусов, предназначенных специально для задачи реферирования художественных текстов на русском языке. С целью проведения экспериментов и оценки различных подходов к генерации аннотаций был создан собственный корпус, состоящий из художественных текстов и соответствующих кратких пересказов. 
В качестве источника для аннотаций был выбран ресурс «Народный Брифли»~\cite{Briefly} — платформа, где пользователи публикуют краткие пересказы литературных произведений. 
Несмотря на вариативность качества и стиля пользовательских аннотаций и наличие нерелевантной информации, такой как учебные вопросы или редакторские замечания, после тщательной предварительной обработки удалось получить достаточно надёжный и чистый набор данных.
Художественные тексты были отобраны из электронной библиотеки LibRuSec — одного из крупнейших русскоязычных ресурсов художественной литературы. 
Отбор произведений осуществлялся на основании наличия аннотаций на выбранном ресурсе \cite{Briefly}. Каждый текст проходил автоматическую предварительную обработку: удалялась метаинформация (например, заголовки, описания глав и технические вставки), 
после чего текст форматировался в единый стандартизированный вид, подходящий для дальнейшего использования в моделях. При сборе текстов возникли некоторые трудности: «Народный Брифли» и LibRuSec хранили информацию об авторах произведений в разном формате.
Где-то была указана только фамилия автора, где-то целый список. Чтобы более точно связать книги с их аннотациями использовалось семантическое сходство: текст имени автора, записанный на Брифли и автора с LibRuSec переводился в эмбеддинги с помощью языковой модели
и сравнивался по косинусному сходству. Таким образом удалось собрать гораздо больше произведений, чем получилось изначально. В таблице \ref{tab:datasets} представлены примеры некоторых различий.
\begin{table}[ht]
\centering
\caption{Сравнение форматов хранения в разных датасетах}
\label{tab:datasets}
\begin{tabular}{lcc}
\toprule
\textbf{Датасет} & \makecell{Название книги} & \makecell{Автор} \\
\midrule
Briefly & Башня Волверден & Аллен \\
LibRuSec & Башня Волверден & [Аллен Грант] \\
\bottomrule
\end{tabular}
\end{table}

Важно отметить, что при создании корпуса использовались только тексты, находящиеся в общественном достоянии или распространяемые свободно с разрешения правообладателей, что обеспечивает соблюдение требований авторского права.
\\Получившийся корпус включал в себя:
\begin{itemize}
  \item более 600 пользовательских пересказов с ресурса «Народный Брифли»;
  \item исходные произведения из электронной библиотеки LibRuSec;
\end{itemize}
Тексты аннотаций проходили автоматическую очистку от HTML‑тегов, комментариев и служебных пометок с помощью LLM~Meta--Llama~3--70B--Instruct. Затем производился поиск по датасету LibRuSec и собиралась коллекция, состоящая из пар "текст книги - аннотация".
На рисунке \ref{fig:text_len} показано распределение текстов в зависимотсти от количества слов в них. На рисунке \ref{fig:ann_len} аналогичная информация об аннотациях.

% ================= ПРИМЕНЕНИЕ МЕТОДОВ =================
\section*{Методология}

\subsection*{Базовые и модифицированные стратегии}

\subsubsection*{Иерархический метод.}
Суть этого метода \cite{hierarchical} заключается в том, что текст разбивается на фрагменты (чанки), для каждого из
которых отдельно генерируется локальная аннотация. 
Эти фрагменты затем объединяются в группы, и из полученных аннотаций снова формируется краткое содержание
следующего уровня. Последний уровень представляет собой итоговую аннотацию всего произведения.

\subsubsection*{«Чертёжный» метод (Text‑Blueprint).}
Данный метод \cite{blueprint} ориентирован на построение промежуточного
плана аннотации перед генерацией текста. План формируется в виде набора вопросноответных пар, что повышает управляемость генерации и обеспечивает структурированность результата.
Сначала модель формирует список вопросов, отражающих ключевые события, темы
и персонажей текста. Далее к каждому вопросу автоматически подбирается краткий
ответ. Эта структура служит планом, по которому генерируется итоговая аннотация.

\subsubsection*{Иерархический метод с фильтрацией узлов.}
Является модифицированным иерархическим методом. Направлен на ускорение генерации за счет удаления потенциально излишних частей информации, что повышает плотность полезной информации в итоговых рефератах. 
Для исключения «воды» и дублирующих фрагментов на каждом уровне иерархии мы теперь выполняем глобальную проверку семантической близости между всеми промежуточными аннотациями. 
\\Алгоритм следующий:

\begin{enumerate}
  \item Пусть на текущем уровне имеются аннотации $\{S_i\}_{i=1}^n$.
  \item Вычисляем эмбеддинги $\mathbf{e}_i = \mathrm{Encoder}(S_i)$ и нормируем их.
  \item Составляем матрицу косинусных сходств
    \[
      M_{ij} = \frac{\mathbf{e}_i \cdot \mathbf{e}_j}{\|\mathbf{e}_i\|\;\|\mathbf{e}_j\|},
      \quad i,j=1,\dots,n.
    \]
  \item Для каждой аннотации $S_j$ находим
    \[
      m_j = \max_{\,i<j} M_{ji},
    \]
    то есть максимальную степень схожести с любой предыдущей в списке.
  \item Если $m_j < \theta$ (где $\theta=0.85$), то сохраняем $S_j$, иначе отбрасываем.
  \item Гарантируем, что $S_1$ всегда остаётся, чтобы не получилось пустого уровня.
\end{enumerate}
Эмбеддинги получаются с помощью SentenceTransformer (модель USER-bge-m3) и при вычислении на GPU обеспечивается высокая скорость обработки.

\subsubsection*{«Чертёжный» метод с кластеризацией вопросов.}
Для снижения числа запросов к модели и повышения структурности:
\begin{enumerate}
  \item Для каждого чанка $C_i$ сгенерировать вопросы $Q_i = \{q_{i1},\dots,q_{im}\}$.
  \item Вычислить эмбеддинги $E_i = \{\mathbf{e}_{i1},\dots,\mathbf{e}_{im}\}$.
  \item Объединить все $\{\mathbf{e}_{ij}\}$ и применить алгоритм K‑means.
  \item Из каждого кластера $c$ случайно выбрать несколько вопросов.
  \item Для кластера $c$ сформировать обобщённый вопрос $Q_c^*$:
    \[
      Q_c^* = \mathrm{LLM}\bigl(\,\text{concat}(q\in c)\bigr).
    \]
  \item Использовать $\{Q_c^*\}$ как чертёж для генерации итоговой аннотации.
\end{enumerate}

Такой подход позволяет уменьшить число обращений к LLM, что позволяет ускорить скорость генераций, как будет показано в таблице \ref{tab:results_models}.

\section*{Оценивание методов}

Для объективного сравнения описанных подходов и моделей в задаче реферирования художественных текстов использовались четыре группы метрик.

\textbf{ROUGE-L} — основана на длине наибольшей общей подпоследовательности (LCS) между сгенерированной аннотацией $S$ и эталонной $R$:
    \[
      \text{Precision} = \frac{\mathrm{LCS}(S,R)}{|S|},\quad
      \text{Recall} = \frac{\mathrm{LCS}(S,R)}{|R|},
    \]
    \[
      \text{ROUGE‑L} = \frac{2\;\text{Precision}\;\cdot\;\text{Recall}}{\text{Precision} + \text{Recall}}.
    \]
\\ \textbf{BERTScore} — семантическое качество на уровне токенов. Для каждой пары токенов предсказания и эталона вычисляется косинусное сходство их эмбеддингов в модели USER‑bge‑m3. Затем:
    \[
      P = \frac{1}{|S|}\sum_{t\in S}\max_{u\in R}\!\mathrm{sim}(e_t, e_u),\quad
      R = \frac{1}{|R|}\sum_{u\in R}\max_{t\in S}\!\mathrm{sim}(e_u, e_t),
    \]
    \[
      \text{BERTScore} = \frac{2\,P\,R}{P+R}.
    \]
\\ \textbf{Полнота покрытия ключевых вопросов (Coverage)} — доля заранее сгенерированных по эталонному тексту вопросов, на которые модель «отвечает» в аннотации:
    \[
      \text{Coverage} = \frac{\#\{q_i\colon P(\text{“да”}\mid q_i,S)\!>\!0.75\}}{N},
    \]
    где $N$ — общее число вопросов, а $P(\text{“да”}\mid q_i,S)$ — вероятность наличия ответа на вопрос $q_i$ в тексте $S$, оцененная LLM.
\\ \textbf{Совпадение ответов (AnswerSimilarity)} — среднее семантическое сходство между сгенерированными ответами $a_i^{\text{pred}}$ и эталонными $a_i^{\text{ref}}$ на те же ключевые вопросы:
    \[
      \text{AnswerSimilarity}
      = \frac{1}{N}\sum_{i=1}^N \mathrm{sim}\bigl(a_i^{\text{pred}},\,a_i^{\text{ref}}\bigr),
    \]
    где $\mathrm{sim}$ — косинусное сходство эмбеддингов, полученных через USER‑bge‑m3.


Использование нескольких метрик, учитывающих как поверхностное совпадение текста (ROUGE‑L), так и глубокое семантическое сходство (BERTScore, AnswerSimilarity), а также степень охвата заранее заданных вопросов (Coverage), обеспечивает всестороннюю и устойчивую оценку качества аннотаций.```

\section*{Параметры экспериментов}

Все представленные в работе измерения выполнены на наборе из 100 художественных произведений, 
отобранных так, чтобы исходные тексты не превышали по длине 800\,000 символов. 
Для всех методов генерируемые аннотации ограничивались максимумом в 500 слов.

Текст на вход разбивался на чанки фиксированного размера в 2000 токенов. 
Токенизация выполнялась с помощью \texttt{AutoTokenizer} модели \texttt{DeepPavlov/rubert-base-cased} в стандартном режиме.
Для воспроизводимости всех случайных процедур использовался фиксированный seed ($random\_seed = 42$).

В \textbf{иерархическом методе с фильтрацией узлов} для оценки избыточности промежуточных аннотаций на каждом уровне вычислялась матрица косинусных сходств между их эмбеддингами.
Порог схожести был установлен равным $\theta=0.85$: если для аннотации $S_j$ существует предыдущая $S_i$ с косинусным сходством выше этого порога, 
то $S_j$ отбрасывается как избыточная. Такой выбор порога обеспечивает компромисс между сохранением значимой информации и устранением дублирования, 
что эмпирически привело к заметному уменьшению объёма промежуточных представлений без существенной деградации качества.

В \textbf{чертёжном методе с кластеризацией вопросов} количество кластеров для K-means выбирается по эвристике, подобранной эмпирически:
\[
n_{\text{clusters}} = \max\!\left(2,\; \left\lceil \sqrt{N_{\text{questions}}} \right\rceil\right),
\]
где $N_{\text{questions}}$ — общее число первоначально сгенерированных вопросов по всем чанкам. 
Гарантируется минимум в два кластера, что позволяет даже при небольших наборах вопросов получать структурированное чертёжное представление.

Временные показатели измерялись как среднее значение (в секундах) времени генерации одной книги по каждому методу для 100 книг. 
В случае всех четырех методов учитывалось суммарное время всех этапов (включая генерацию промежуточных аннотаций / планов, фильтрацию и финальную агрегацию).

Проводились первоначальные замеры скорости работы методов на небольших текстах, полученные результаты в секундах (среднее по трем запускам) представлены в таблице \ref{tab:timing}. 
Результаты подтверждают, что модификации позволяют повысить скорость генерации.
\begin{table}[ht]
\centering
\caption{Время генерации аннотации (в секундах) для текста размером 81{,}049 символов (11 чанков). Усреднено по трём запускам.}
\label{tab:timing}
\begin{tabular}{lcccc}
\toprule
\textbf{Модель} & \makecell{Иерархический} & \makecell{Иерархический\\с фильтрацией} & \makecell{Чертежный} & \makecell{Чертежный\\с кластеризацией} \\
\midrule
RuadaptQwen2.5-7B-Lite-Beta & 84.64 & 25.70 & 103.66 & 78.99 \\

DeepSeek V3 & 237.83 & 72.42 & 292.80 & 268.75 \\
Qwen3-235B-A22B & 113.24 & 39.45 & 215.63 & 145.20 \\
tpro & 472.23 & 127.38 & 421.65 & 185.94 \\
yagpt5lite & 34.17 & 14.08 & 99.70 & 27.26 \\
\bottomrule
\end{tabular}
\end{table}

\section*{Результаты}

В таблице \ref{tab:results_models} представлены сравнительные метрики качества автоматического пересказа книг разными моделями и методами обработки. Для каждой комбинации модели и метода измерялись BERTScore, ROUGEL, Answer Coverage и 
Similarity, а также время генерации (среднее) на 100 примерах, одинаковых для всех замеров. Лучше всего себя показала модель Qwen3235B: она продемонстировала самые высокие показатели в покрытие вопросов и сходстве ответов.
В то же время важно отметить, что среди всех методов лучшим образом в соотношение качество и время обработки себя показывает иерархический метод с фильтрацией узлов. Он позволяет существенно ускорить время обработки (например, почти в два раза для модели DeepSeek V3), и по сравнению с 
чертежным методом, который в среднем показывал лучшие результаты, не сильно отстает по показателям. Исключением стала лишь модель Qwen3235B, так как она показала лучший результат среди всех моделей на базовом чертежном методе.
Наши эксперименты показали, что иерархический метод с фильтрацией узлов обеспечивает наилучший компромисс между скоростью и качеством генерации.


\begin{table}[ht]
\centering
\small
\setlength{\tabcolsep}{4pt}
\caption{Результаты по методам и моделям (переставленные столбцы)}
\label{tab:results_models}

\begin{tabular}{llcccc}
\toprule
Модель & Метрики &
\makecell{Иерархический} &
\makecell{Чертежный} &
\makecell{Иерархический \\ с фильтрацией} &
\makecell{Чертежный \\ с кластеризацией} \\
\midrule
\multirow{5}{*}{RuadaptQwen2.5-7B-Lite-Beta}
 & bertscore & 55.4 ± 2.9 & 56.1 ± 4.9 & 55.8 ± 2.9 & 54.0 ± 4.0 \\
 & rouge-l   & 8.6 ± 2.5 & 10.1 ± 3.9 & 8.7 ± 2.5 & 7.7 ± 2.8 \\
 & coverage  & 19.66 ± 17.77 & 24.94 ± 21.08 & 20.31 ± 17.95 & 15.51 ± 14.83 \\
 & similarity& 15.16 ± 14.11 & 20.03 ± 17.50 & 15.94 ± 14.39 & 12.23 ± 12.30 \\
 & time      & 68.86 ± 64.85 & 126.84 ± 145.74 & 53.59 ± 47.28 & 76.66 ± 91.78 \\
\midrule
\multirow{5}{*}{yagpt5lite}
 & bertscore & 62.5 ± 3.5 & 61.1 ± 3.8 & 62.1 ± 3.2 & 61.5 ± 3.3 \\
 & rouge-l   & 16.9 ± 5.1 & 15.8 ± 5.1 & 16.4 ± 4.7 & 14.3 ± 4.4 \\
 & coverage  & 36.85 ± 19.40 & 33.17 ± 21.58 & 31.75 ± 20.06 & 24.28 ± 16.95 \\
 & similarity& 29.69 ± 16.43 & 26.58 ± 18.13 & 25.60 ± 16.85 & 19.70 ± 14.29 \\
 & time      & 31.02 ± 28.51 & 113.34 ± 123.78 & 27.39 ± 28.05 & 42.15 ± 56.50 \\
\midrule
\multirow{5}{*}{RuadaptQwen3-32B-Instruct-v2}
 & bertscore & 57.3 ± 2.9 & 58.9 ± 3.6 & 57.7 ± 3.3 & 55.3 ± 3.3 \\
 & rouge-l   & 11.0 ± 2.4 & 10.6 ± 3.2 & 10.7 ± 2.4 & 7.8 ± 2.1 \\
 & coverage  & 33.12 ± 21.50 & 33.18 ± 22.83 & 32.19 ± 22.52 & 17.72 ± 15.23 \\
 & similarity& 25.25 ± 16.94 & 26.21 ± 18.22 & 24.82 ± 17.74 & 13.97 ± 12.39 \\
 & time      & 218.30 ± 195.16 & 379.24 ± 500.40 & 166.79 ± 164.61 & 286.35 ± 395.97 \\
\midrule
\multirow{5}{*}{tpro}
 & bertscore & 59.4 ± 3.0 & 59.0 ± 4.9 & 59.5 ± 3.3 & 58.2 ± 3.7 \\
 & rouge-l   & 13.8 ± 3.1 & 14.7 ± 4.9 & 13.5 ± 3.0 & 11.8 ± 3.9 \\
 & coverage  & 40.27 ± 20.23 & 40.83 ± 22.42 & 37.13 ± 20.72 & 26.03 ± 18.44 \\
 & similarity& 31.77 ± 16.63 & 32.60 ± 18.57 & 29.44 ± 16.83 & 20.83 ± 15.26 \\
 & time      & 367.32 ± 324.49 & 592.39 ± 772.19 & 267.73 ± 253.34 & 247.59 ± 361.20 \\
 \midrule
\multirow{5}{*}{Qwen3-235B-A22B}
 & bertscore & 61.2 ± 3.0 & 61.6 ± 3.3 & 60.9 ± 2.7 & 59.3 ± 3.4 \\
 & rouge-l   & 14.9 ± 4.0 & 15.8 ± 4.5 & 14.8 ± 3.7 & 12.2 ± 3.6 \\
 & coverage  & 52.48 ± 20.79 & \textbf{54.78 ± 21.16} & 44.54 ± 23.03 & 30.19 ± 21.96 \\
 & similarity& 41.68 ± 17.18 & 43.99 ± 17.54 & 35.67 ± 18.87 & 24.10 ± 17.62 \\
 & time      & 103.49 ± 97.30 & 230.35 ± 271.03 & 83.06 ± 102.05 & 158.30 ± 196.35 \\
\midrule
\multirow{5}{*}{DeepSeek V3}
 & bertscore & 60.0 ± 3.1 & 58.0 ± 4.0 & 60.0 ± 2.9 & 58.4 ± 3.6 \\
 & rouge-l   & 13.7 ± 3.9 & 12.6 ± 4.6 & 13.5 ± 3.7 & 11.2 ± 3.9 \\
 & coverage  & \textbf{53.57 ± 21.66} & 40.19 ± 23.68 & \textbf{45.00 ± 23.03} & \textbf{34.68 ± 23.77} \\
 & similarity& 42.38 ± 17.73 & 32.31 ± 19.33 & 35.64 ± 18.88 & 27.76 ± 19.75 \\
 & time      & 196.77 ± 187.85 & 315.67 ± 321.89 & 147.21 ± 146.4 & 132.60 ± 197.25 \\
\bottomrule
\end{tabular}
\end{table}


\subsection*{Анализ и сравнение результатов.}
Разброс значений метрики QA можно проиллюстрировать на примере работы одной и той же модели (DeepSeek V3) в рамках иерархического метода.
В качестве иллюстрации взяты две аннотации к произведениям <<И грянул гром>> и <<Кастрюк>>. 
В первом случае модель получила высокий результат, ответив на все, кроме одного вопроса; во второй 
аннотации содержались ответы только на два вопроса из одиннадцати, что привело к низкому показателю. В таблице \ref{tab:annotations} показаны две аннотации. 
Для краткости в них выделены только основные моменты, которые
повлияли на итоговую метрику. 
Сравнение показывает возможную причину столь значительного расхождения: аннотация к рассказу <<Кастрюк>> изобилует лирическими отступлениями и художественными деталями,
из-за чего суть произведения сложно уловить и модель отвлекается от фиксации главных фактов,
тогда как в "И грянул гром" события изложены последовательно и структурировано, 
а основные элементы сюжета чётко перечислены, что упрощает их сохранение и воспроизведение.
\begin{table}[h!]
\centering
\begin{tabular}{|p{0.15\linewidth}|p{0.8\linewidth}|}
\hline
\makecell{\textbf{Название}} & \makecell{\textbf{Текст}} \\ \hline

\makecell{\textbf{И грянул} \\ \textbf{гром}} & \dots
Главный герой, Экельс, азартный и самоуверенный охотник, платит огромную сумму за возможность отправиться на 60 миллионов лет назад, чтобы убить тираннозавра. 
Перед путешествием гид Тревис строго предупреждает его о правилах: ни в коем случае нельзя сходить с антигравитационной Тропы или вмешиваться в естественный ход событий, 
так как малейшее нарушение может катастрофически изменить будущее.\dots Тревис объясняет хрупкость временного баланса: 
даже гибель одной мыши способна уничтожить целые виды, а значит, и изменить историю человечества. Группа выслеживает тираннозавра, помеченного красной краской — это знак, 
что его убийство не повлияет на будущее. Однако при виде гигантского хищника Экельс впадает в панику, сходит с Тропы и случайно раздавливает бабочку\dots 
По возвращении в 2055 \dots мир изменился до неузнаваемости: язык стал грубым, атмосфера — тяжёлой, а вместо умеренного президента Кейта у власти стоит жестокий диктатор Дойчер. 
Экельс осознаёт, что его неосторожность спровоцировала «эффект бабочки» — раздавленное насекомое вызвало цепь событий, исказивших историю. 
В отчаянии он умоляет исправить ошибку, но Тревис, понимая необратимость последствий, поднимает ружьё. \dots
 \\ \hline

\textbf{Кастрюк} & \dots Действие рассказа разворачивается в русской деревне ранней весной, 
где природа пробуждается, но жизнь людей остаётся тяжёлой и однообразной. Главный герой — старик Семён, прозванный Кастрюком, — 
доживает свои дни в одиночестве, терзаемый воспоминаниями о былой силе и сожалениями о нынешней немощности. Когда-то он славился как лучший работник в округе, 
но теперь, дряхлый и забытый, вынужден оставаться в стороне, пока односельчане трудятся в поле. Его единственная отрада — внучка Дашка, добрая и впечатлительная девочка, 
которая прибегает к нему, испугавшись барчуков из соседнего имения Залесное. Кастрюк успокаивает её, и они вместе отправляются за деревню, где старик, любуясь весенней природой, 
пытается отвлечься от гнетущих мыслей. \dots
Лишь к вечеру, уговорив сына отпустить его в ночное (пасти лошадей), Кастрюк обретает краткую радость. На свободе, среди ребятишек и под звёздным небом, он чувствует себя почти молодым. 
У пруда кобыла пьёт воду, отражая закат, а сам старик, глядя на Млечный Путь, шепчет молитву — будто вновь обретает связь с миром и утраченную гармонию. 
Но это лишь мимолётное утешение: завтра его снова ждёт беспросветное одиночество и осознание собственной ненужности. \dots
  \\ \hline

\end{tabular}
\caption{Сравнение двух аннотаций}
\label{tab:annotations}
\end{table}
\FloatBarrier
Переходя к сравнению между моделями, можно отметить, что в целом DeepSeek V3 показывает лучшие показатели, чем модели меньшей категории, однако, если сравнивать чертежный метод, то в 30\% случаев модель 
RuadaptQwen3 показывает лучшие результаты, а tpro в 43 (из 100). Для сравнения можно взять аннотацию по произведению <<И грянул гром>>, созданную с использованием чертежного метода, 
небольшие вырезки которой приведены в таблице \ref{tab:annotations_deepseek_vs_others}.
В то время как аннотация, созданная моделью DeepSeek V3 больше похожа на перечесление основных событий через нумерованный список,
текст у моделей RuadaptQwen3 и tpro является связным пересказом текста, раскрывающим все основные события сюжета.

\begin{table}[h!]
\centering
\begin{tabular}{|p{0.15\linewidth}|p{0.8\linewidth}|}
\hline
\makecell{\textbf{Модель}} & \makecell{\textbf{Текст}} \\ \hline

\makecell{RuadaptQwen3} & "Компания «Сафари во Времени» организует платные экскурсии в прошлое для охоты на динозавров, 
используя машины времени, способные перемещаться между эпохами.  
Клиенты обязаны соблюдать строгие правила: следовать по металлической тропе,
избегать контакта с природой и убивать только помеченное красными маркерам животное\dots
 \\ \hline

\makecell{tpro} & "В тексте главный герой, Экельс, отправляется на сафари во времени с целью убить динозавра Tyrannosaurus rex. 
Компания, организующая сафари, гарантирует только динозавров и строго запрещает охотникам сходить 
с Тропы в прошлом, чтобы избежать изменения будущего и не уничтожать важное звено в развитии вида. 
Мистер Тревис, проводник сафари, объясняет, что даже уничтожение одной мыши может привести к исчезновению всех её потомков \dots
 \\ \hline

\makecell{DeepSeek V3} & "**Краткое содержание по плану:** 1. **Экельс** — охотник \dots
 2. **Компания «Сафари во времени»** организует охоту в прошлом \dots
 3. **Тревис** — проводник, контролирующий экспедицию. \dots
  \\ \hline

\end{tabular}
\caption{Сравнение аннотаций разных моделей}
\label{tab:annotations_deepseek_vs_others}
\end{table}

Следует отметить, что хоть чертежный метод требует больше времени на обработку и для некоторых моделей прирост результата либо незначительный, либо хуже, лучшего результата удалось
добиться именно этим методом с помощью большой модели Qwen3235B, как было показано в таблице \ref{tab:results_models}. Для сравнения качества аннотаций можно взять рассказ <<Барбос и Жулька>> - в иерархическом методе
модель Qwen3235B посчитала, что <<Жулька>> - не собака, а лошадь. Также, например, DeepSeek V3 более строго следует шаблону чертежного метода и вместо связного текста пересказа получается нумерованный список
пунктов с ключевыми событиями и главными героями. Однако Qwen3235B пишет обычный текст, без списков. Таким образом, чертежный метод без модификаций позволил достичь наилучшего результата с использованием лучшей доступной моделью - Qwen3235B.

% -------------------------------------------------------

\section*{Заключение}
В заключение, был создан первый открытый датасет, объединяющий тексты книг и аннотации к ним с открытого ресурса <<Народный Брифли>>. 
В работе предложены два улучшенных подхода к реферированию художественных текстов с использованием LLM: иерархический с фильтрацией и чертёжный с кластеризацией. 
Иерархический метод с фильтрацией позволяет ускорить генерацию при минимальной потере качества, 
что делает этот метод пригодным для обработки длинных произведений в условиях ограниченного контекста моделей.  

Сравнительный анализ показал, что крупные модели, такие как DeepSeek~V3 и Qwen3235B, в большинстве случаев обеспечивают более высокое покрытие QA и 
большую полноту аннотаций по сравнению с компактными моделями, особенно в иерархическом и чертёжном методах. 
Однако для некоторых типов текстов и методов (например, базовый чертёжный) более компактные модели, такие как RuadaptQwen3, 
могут демонстрировать конкурентоспособное качество при меньших вычислительных затратах. 
Таким образом, выбор модели следует определять исходя из баланса между доступными ресурсами, требованиями к качеству и характером обрабатываемых текстов.



%-------РЕФЕРЕНСЫ---------
\begin{thebibliography}{99}
\bibitem{Briefly}
\textit{Народный Брифли.}  
Электронная библиотека кратких пересказов литературных произведений.  
\url{https://wiki.briefly.ru/} (дата обращения: 16.07.2025).


\bibitem{blueprint}
\textit{Чертежный метод.}  
Text-Blueprint: An Interactive Platform for Plan-based Conditional Generation / Fantine Huot, Joshua Maynez, Shashi Narayan et al. // Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics:
System Demonstrations / Ed. by Danilo Croce, Luca Soldaini. — Dubrovnik, Croatia: Association for Computational Linguistics, 2023. — . — Pp. 105–116. https:
//aclanthology.org/2023.eacl-demo.13/.

\bibitem{hierarchical}
\textit{Иерархический метод.}  
Wu J. et al. Recursively Summarizing Books with Human Feedback //arXiv e-prints. – 2021. – С. arXiv: 2109.10862.

\end{thebibliography}

\renewcommand\refname{References}


\begin{thebibliography}{99}
\bibitem{Briefly_e}
\textit{Народный Брифли.}  
Электронная библиотека кратких пересказов литературных произведений.  
\url{https://wiki.briefly.ru/} (дата обращения: 16.07.2025).

\bibitem{blueprint_e}
\textit{Чертежный метод.}  
Text-Blueprint: An Interactive Platform for Plan-based Conditional Generation / Fantine Huot, Joshua Maynez, Shashi Narayan et al. // Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics:
System Demonstrations / Ed. by Danilo Croce, Luca Soldaini. — Dubrovnik, Croatia: Association for Computational Linguistics, 2023. — . — Pp. 105–116. https:
//aclanthology.org/2023.eacl-demo.13/.

\bibitem{hierarchical_e}
\textit{Иерархический метод.}  
Wu J. et al. Recursively Summarizing Books with Human Feedback //arXiv e-prints. – 2021. – С. arXiv: 2109.10862.

\end{thebibliography}

\end{document}